@misc{ronneberger2015unetconvolutionalnetworksbiomedical,
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  year          = 2015,
  booktitle     = {MICCAI (3)},
  publisher     = {Springer},
  volume        = 9351,
  pages         = {234--241},
  url           = {https://arxiv.org/abs/1505.04597},
  eprint        = {1505.04597},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{kingma2022autoencodingvariationalbayes,
  title         = {Auto-Encoding Variational Bayes},
  author        = {Diederik P Kingma and Max Welling},
  year          = 2022,
  url           = {https://arxiv.org/abs/1312.6114},
  eprint        = {1312.6114},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}
@misc{ho2020denoisingdiffusionprobabilisticmodels,
  title         = {Denoising Diffusion Probabilistic Models},
  author        = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
  year          = 2020,
  booktitle     = {Advances in Neural Information Processing Systems},
  publisher     = {Curran Associates, Inc.},
  volume        = 33,
  pages         = {6840--6851},
  url           = {https://arxiv.org/abs/2006.11239},
  eprint        = {2006.11239},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  editor        = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin}
}
@inproceedings{deng2009imagenet,
  title     = {ImageNet: A large-scale hierarchical image database},
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  year      = 2009,
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  volume    = {},
  number    = {},
  pages     = {248--255},
  doi       = {10.1109/CVPR.2009.5206848},
  keywords  = {Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine}
}
@misc{heusel2018ganstrainedtimescaleupdate,
  title         = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author        = {Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
  year          = 2018,
  url           = {https://arxiv.org/abs/1706.08500},
  eprint        = {1706.08500},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{lin2015microsoftcococommonobjects,
  title         = {Microsoft COCO: Common Objects in Context},
  author        = {Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
  year          = 2015,
  url           = {https://arxiv.org/abs/1405.0312},
  eprint        = {1405.0312},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{lin2023designbenchexploringbenchmarkingdalle,
  title         = {DEsignBench: Exploring and Benchmarking DALL-E 3 for Imagining Visual Design},
  author        = {Kevin Lin and Zhengyuan Yang and Linjie Li and Jianfeng Wang and Lijuan Wang},
  year          = 2023,
  url           = {https://arxiv.org/abs/2310.15144},
  eprint        = {2310.15144},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{yasunaga2022retrievalaugmentedmultimodellanguagemodeling,
  title        = {Retrieval-Augmented Multimodal Language Modeling},
  author       = {Michihiro Yasunaga and Armen Aghajanyan and Weijia Shi and Rich James and Jure Leskovec and Percy Liang and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},
  year         = 2022,
  url          = {https://paperswithcode.com/paper/retrieval-augmented-multimodal-language},
  primaryclass = {cs.CV}
}
@inproceedings{ko2023largescaletexttoimagegenartionmodelsforvisualartists,
  title     = {Large-scale Text-to-Image Generation Models for Visual Artists’ Creative Works},
  author    = {Hyung-Kwon Ko and Gwanmo Park and Hyeon Jeon and Jaemin Jo and Juho Kim and Jinwook Seo},
  year      = 2023,
  booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
  location  = {Sydney, NSW, Australia},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  series    = {IUI '23},
  pages     = {919–933},
  doi       = {10.1145/3581641.3584078},
  isbn      = 9798400701061,
  url       = {https://doi.org/10.1145/3581641.3584078},
  numpages  = 15,
  keywords  = {DALL-E, Large-scale text-to-image generation model, interview study, literature review, visual artists}
}
@article{vimpari2023texttoimagegenerationaibygameprofessionals,
  title     = {“{A}n Adapt-or-Die Type of Situation”: Perception, Adoption, and Use of Text-to-Image-Generation AI by Game Industry Professionals},
  author    = {Vimpari, Veera and Kultima, Annakaisa and Hämäläinen, Perttu and Guckelsberger, Christian},
  year      = 2023,
  month     = sep,
  journal   = {Proceedings of the ACM on Human-Computer Interaction},
  publisher = {Association for Computing Machinery (ACM)},
  volume    = 7,
  number    = {CHI PLAY},
  pages     = {131–164},
  doi       = {10.1145/3611025},
  issn      = {2573-0142},
  url       = {http://dx.doi.org/10.1145/3611025}
}
@book{sekban2022artandarchtitecture,
  title     = {Art and Architecture: Theory, Practice and Experience},
  author    = {Demet Ulku Gulpinar Sekban and G{\"u}ls{\"u}m Ta{\c{c}} and Hatice Kalfao{\u{g}}lu Hatipo{\u{g}}lu and P{\i}nar {\"O}zge Parlak  and Banu {\c{C}}i{\c{c}}ek Kurdo{\u{g}}lu and Rifat Olgun and Serap Yilmaz and Nida Kurak and Elif Merve Alpak and Tu{\u{g}}ba D{\"u}zenl{\.{i}} and Elif Bayramo{\u{g}}lu and Seyhan Seyhan and Erdem Yildirim and S. Asal Hojjat{\.{i}} and {\.I}lkay {\"O}zdem{\.{i}}r and Didem G{\"u}ne{\c{s}} Yilmaz and Kamuran Karaa{\u{g}}a{\c{c}} and Gonca B{\"u}y{\"u}kmih{\c{c}}i and Ay{\c{s}}eg{\"u}l Ak{\c{s}}eh{\.{i}}rl{\.{i}}o{\u{g}}lu},
  year      = 2022,
  publisher = {Livre de Lyon},
  isbn      = {978-2-382-36493-2}
}
@article{vartiainen2023aiincraftseducation,
  title     = {Using artificial intelligence in craft education: crafting with text-to-image generative models},
  author    = {Henriikka Vartiainen and Matti Tedre},
  year      = 2023,
  journal   = {Digital Creativity},
  publisher = {CAA Website},
  volume    = 34,
  number    = 1,
  pages     = {1--21},
  doi       = {10.1080/14626268.2023.2174557},
  url       = {https://doi.org/10.1080/14626268.2023.2174557},
  eprint    = {https://doi.org/10.1080/14626268.2023.2174557}
}
@article{miao2023aiintourism,
  title    = {Text-to-image AI tools and tourism experiences},
  author   = {Li Miao and Fiona X. Yang},
  year     = 2023,
  journal  = {Annals of Tourism Research},
  volume   = 102,
  pages    = 103642,
  doi      = {https://doi.org/10.1016/j.annals.2023.103642},
  issn     = {0160-7383},
  url      = {https://www.sciencedirect.com/science/article/pii/S0160738323001159},
  keywords = {Artificial intelligence, Generative AI, Text-to-image, Tourism experience}
}
@article{correctiv2023pentagonexplosion,
  title   = {{K}ünstliche {I}ntelligenz: {W}ie ein {F}ake-{F}oto einer {E}xplosion am {P}entagon um die {W}elt ging},
  author  = {Kimberly Nicolaus},
  year    = 2023,
  month   = may,
  journal = {Correctiv},
  url     = {https://correctiv.org/faktencheck/2023/05/24/kuenstliche-intelligenz-wie-ein-fake-foto-einer-explosion-am-pentagon-um-die-welt-ging/},
  note    = {[Accessed 27-08-2024]},
  date    = {2023-05-24}
}
@misc{neupane2023impactsriskgenerativeai,
  title         = {Impacts and Risk of Generative AI Technology on Cyber Defense},
  author        = {Subash Neupane and Ivan A. Fernandez and Sudip Mittal and Shahram Rahimi},
  year          = 2023,
  url           = {https://arxiv.org/abs/2306.13033},
  eprint        = {2306.13033},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}
@inproceedings{naik2023socialbiasesthroughtexttoimage,
  title     = {Social Biases through the Text-to-Image Generation Lens},
  author    = {Ranjita Naik and Besmira Nushi},
  year      = 2023,
  booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
  location  = {Montr\'{e}al, QC, Canada},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  series    = {AIES '23},
  pages     = {786–808},
  doi       = {10.1145/3600211.3604711},
  isbn      = 9798400702310,
  url       = {https://doi.org/10.1145/3600211.3604711},
  numpages  = 23,
  keywords  = {representational fairness, social biases, text-to-image generation}
}
@inproceedings{mim2024impactoftexttoimagetoolsinglobalsouth,
  title     = {In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South},
  author    = {Nusrat Jahan Mim and Dipannita Nandi and Sadaf Sumyia Khan and Arundhuti Dey and Syed Ishtiaque Ahmed},
  year      = 2024,
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
  location  = {Honolulu, HI, USA},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  series    = {CHI '24},
  doi       = {10.1145/3613904.3641951},
  isbn      = 9798400703300,
  url       = {https://doi.org/10.1145/3613904.3641951},
  articleno = 474,
  numpages  = 18,
  keywords  = {Architecture, Art, Artificial Intelligence, Generative AI, Image, Urban Design}
}
@article{cnn2023gettyimagesvsstabilityai,
  title   = {Getty Images suing the makers of popular AI art tool for allegedly stealing photos},
  author  = {Jennifer Korn},
  year    = 2023,
  month   = jan,
  journal = {CNN Business},
  url     = {https://edition.cnn.com/2023/01/17/tech/getty-images-stability-ai-lawsuit/index.html},
  note    = {[Accessed 27-08-2024]},
  date    = {2023-01-18}
}
@inproceedings{devlin2019bert,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year      = 2019,
  month     = jun,
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  publisher = {Association for Computational Linguistics},
  address   = {Minneapolis, Minnesota},
  pages     = {4171--4186},
  doi       = {10.18653/v1/N19-1423},
  url       = {https://aclanthology.org/N19-1423},
  editor    = {Jill Burstein  and Christy Doran  and Thamar Solorio}
}
@inproceedings{rombach2022stablediffusion,
  title     = {High-Resolution Image Synthesis with Latent Diffusion Models},
  author    = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  year      = 2022,
  booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  volume    = {},
  number    = {},
  pages     = {10674--10685},
  doi       = {10.1109/CVPR52688.2022.01042},
  keywords  = {Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control;Image and video synthesis and generation}
}
@inproceedings{ding2021cogviewmasteringtexttoimagegeneration,
  title     = {CogView: Mastering text-to-image generation via transformers},
  author    = {Ming Ding and Zhuoyi Yang and Wenyi Hong and Wendi Zheng and Chang Zhou and Da Yin and Junyang Lin and Xu Zou and Zhou Shao and Hongxia Yang and Jie Tang},
  year      = 2024,
  booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  series    = {NIPS '21},
  isbn      = 9781713845393,
  abstract  = {Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.},
  articleno = 1516,
  numpages  = 14
}
@misc{zhou2022lafitelanguagefreetrainingtexttoimage,
  title         = {LAFITE: Towards Language-Free Training for Text-to-Image Generation},
  author        = {Yufan Zhou and Ruiyi Zhang and Changyou Chen and Chunyuan Li and Chris Tensmeyer and Tong Yu and Jiuxiang Gu and Jinhui Xu and Tong Sun},
  year          = 2022,
  url           = {https://arxiv.org/abs/2111.13792},
  eprint        = {2111.13792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{rezende2014stochasticbackpropagationapproximateinference,
  title     = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
  author    = {Danilo Jimenez Rezende and Shakir Mohamed and Daan Wierstra},
  year      = 2014,
  booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
  location  = {Beijing, China},
  publisher = {JMLR.org},
  series    = {ICML'14},
  pages     = {II–1278–II–1286}
}
@inproceedings{gafni2022makeascenescenebasedtexttoimagegeneration,
  title         = {Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors},
  author        = {Oran Gafni and Adam Polyak and Oron Ashual and Shelly Sheynin and Devi Parikh and Yaniv Taigman},
  year          = 2022,
  booktitle     = {Computer Vision -- ECCV 2022},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {89--106},
  isbn          = {978-3-031-19784-0},
  url           = {https://arxiv.org/abs/2203.13131},
  eprint        = {2203.13131},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{obukhov2020torchfidelity,
  title     = {High-fidelity performance metrics for generative models in PyTorch},
  author    = {Anton Obukhov and Maximilian Seitzer and Po-Wei Wu and Semen Zhydenko and Jonathan Kyl and Elvis Yu-Jing Lin},
  year      = 2020,
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.4957738},
  url       = {https://github.com/toshas/torch-fidelity},
  note      = {Version: 0.3.0, DOI: 10.5281/zenodo.4957738},
  version   = {v0.3.0}
}
@inproceedings{vaswani2023attentionneed,
  title     = {Attention is all you need},
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year      = 2017,
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  location  = {Long Beach, California, USA},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  series    = {NIPS'17},
  pages     = {6000–6010},
  isbn      = 9781510860964,
  numpages  = 11
}
@book{firth1962studiesinlinguisticanalysis,
  title     = {Studies in Linguistic Analysis - Special Volume of the Philological Society},
  author    = {John Rupert Firth},
  year      = 1962,
  publisher = {Blackwell},
  address   = {Oxford}
}
@inproceedings{alaluf2022hyperstylestyleganinversionhypernetworks,
  title     = {Hyperstyle: Stylegan inversion with hypernetworks for real image editing},
  author    = {Alaluf, Yuval and Tov, Omer and Mokady, Ron and Gal, Rinon and Bermano, Amit},
  year      = 2022,
  booktitle = {Proceedings of the IEEE/CVF conference on computer Vision and pattern recognition},
  pages     = {18511--18521}
}
@inproceedings{dinh2022hyperinverterimprovingstyleganinversion,
  title     = {Hyperinverter: Improving stylegan inversion via hypernetwork},
  author    = {Dinh, Tan M and Tran, Anh Tuan and Nguyen, Rang and Hua, Binh-Son},
  year      = 2022,
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {11389--11398}
}
@inproceedings{houlsby2019parameterefficienttransferlearningnlp,
  title        = {Parameter-efficient transfer learning for NLP},
  author       = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  year         = 2019,
  booktitle    = {International conference on machine learning},
  pages        = {2790--2799},
  organization = {PMLR}
}
@inproceedings{stickland2019bertpalsprojectedattention,
  title        = {Bert and pals: Projected attention layers for efficient adaptation in multi-task learning},
  author       = {Stickland, Asa Cooper and Murray, Iain},
  year         = 2019,
  booktitle    = {International Conference on Machine Learning},
  pages        = {5986--5995},
  organization = {PMLR}
}
@article{rosenfeld2018incrementallearningdeepadaptation,
  title     = {Incremental learning through deep adaptation},
  author    = {Rosenfeld, Amir and Tsotsos, John K},
  year      = 2018,
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  publisher = {IEEE},
  volume    = 42,
  number    = 3,
  pages     = {651--663}
}
@inproceedings{rebuffi2018efficientparametrizationmultidomaindeep,
  title     = {Efficient parametrization of multi-domain deep neural networks},
  author    = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  year      = 2018,
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {8119--8127}
}
@inproceedings{li2022exploringplainvisiontransformer,
  title        = {Exploring plain vision transformer backbones for object detection},
  author       = {Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  year         = 2022,
  booktitle    = {European conference on computer vision},
  pages        = {280--296},
  organization = {Springer}
}
@misc{li2021benchmarkingdetectiontransferlearning,
  title         = {Benchmarking Detection Transfer Learning with Vision Transformers},
  author        = {Yanghao Li and Saining Xie and Xinlei Chen and Piotr Dollar and Kaiming He and Ross Girshick},
  year          = 2021,
  url           = {https://arxiv.org/abs/2111.11429},
  eprint        = {2111.11429},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{chen2023visiontransformeradapterdense,
  title         = {Vision Transformer Adapter for Dense Predictions},
  author        = {Zhe Chen and Yuchen Duan and Wenhai Wang and Junjun He and Tong Lu and Jifeng Dai and Yu Qiao},
  year          = 2023,
  url           = {https://arxiv.org/abs/2205.08534},
  eprint        = {2205.08534},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@article{mou2023t2iadapterlearningadaptersdig,
  title={T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models},
  author={Chong Mou and Xintao Wang and Liangbin Xie and Jing Zhang and Zhongang Qi and Ying Shan and Xiaohu Qie},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.08453},
  url={https://api.semanticscholar.org/CorpusID:256900833}
}
@inproceedings{mallya2018piggybackadaptingsinglenetwork,
  title     = {Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author    = {Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  year      = 2018,
  booktitle = {Proceedings of the European conference on computer vision (ECCV)},
  pages     = {67--82}
}
@inproceedings{mallya2018packnetaddingmultipletasks,
  title     = {Packnet: Adding multiple tasks to a single network by iterative pruning},
  author    = {Mallya, Arun and Lazebnik, Svetlana},
  year      = 2018,
  booktitle = {Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages     = {7765--7773}
}
@inproceedings{serrà2018overcomingcatastrophicforgettinghard,
  title        = {Overcoming catastrophic forgetting with hard attention to the task},
  author       = {Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  year         = 2018,
  booktitle    = {International conference on machine learning},
  pages        = {4548--4557},
  organization = {PMLR}
}
@inproceedings{zhang2023addingconditionalcontroltexttoimage,
  title     = {Adding conditional control to text-to-image diffusion models},
  author    = {Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {3836--3847}
}
@inproceedings{zhang2020sidetuningbaselinenetworkadaptation,
  title        = {Side-tuning: a baseline for network adaptation via additive side networks},
  author       = {Zhang, Jeffrey O and Sax, Alexander and Zamir, Amir and Guibas, Leonidas and Malik, Jitendra},
  year         = 2020,
  booktitle    = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages        = {698--714},
  organization = {Springer}
}
@misc{hu2021loralowrankadaptationlarge,
  title         = {LoRA: Low-Rank Adaptation of Large Language Models},
  author        = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  year          = 2021,
  url           = {https://arxiv.org/abs/2106.09685},
  eprint        = {2106.09685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{aghajanyan2020intrinsicdimensionalityexplainseffectiveness,
  title         = {Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
  author        = {Armen Aghajanyan and Luke Zettlemoyer and Sonal Gupta},
  year          = 2020,
  url           = {https://arxiv.org/abs/2012.13255},
  eprint        = {2012.13255},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{li2018measuringintrinsicdimensionobjective,
  title         = {Measuring the Intrinsic Dimension of Objective Landscapes},
  author        = {Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
  year          = 2018,
  url           = {https://arxiv.org/abs/1804.08838},
  eprint        = {1804.08838},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{lecun2015deeplearning,
  title     = {Deep learning},
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year      = 2015,
  journal   = {nature},
  publisher = {Nature Publishing Group UK London},
  volume    = 521,
  number    = 7553,
  pages     = {436--444}
}
@misc{karras2018progressivegrowinggansimproved,
  title         = {Progressive Growing of GANs for Improved Quality, Stability, and Variation},
  author        = {Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  year          = 2018,
  url           = {https://arxiv.org/abs/1710.10196},
  eprint        = {1710.10196},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}
@inproceedings{sohldickstein2015deepunsupervisedlearningusing,
  title        = {Deep unsupervised learning using nonequilibrium thermodynamics},
  author       = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  year         = 2015,
  journal      = {CoRR},
  booktitle    = {International conference on machine learning},
  volume       = {abs/1503.03585},
  pages        = {2256--2265},
  organization = {PMLR}
}
@article{dhariwal2021diffusionmodelsbeatgans,
  title   = {Diffusion models beat gans on image synthesis},
  author  = {Dhariwal, Prafulla and Nichol, Alexander},
  year    = 2021,
  journal = {Advances in neural information processing systems},
  volume  = 34,
  pages   = {8780--8794}
}
@article{kingma2023variationaldiffusionmodels,
  title   = {Variational diffusion models},
  author  = {Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  year    = 2021,
  journal = {Advances in neural information processing systems},
  volume  = 34,
  pages   = {21696--21707}
}
@inproceedings{radford2021learningtransferablevisualmodels,
  title        = {Learning transferable visual models from natural language supervision},
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  year         = 2021,
  booktitle    = {International conference on machine learning},
  pages        = {8748--8763},
  organization = {PMLR}
}
@misc{nichol2022glidephotorealisticimagegeneration,
  title         = {GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  author        = {Alex Nichol and Prafulla Dhariwal and Aditya Ramesh and Pranav Shyam and Pamela Mishkin and Bob McGrew and Ilya Sutskever and Mark Chen},
  year          = 2022,
  url           = {https://arxiv.org/abs/2112.10741},
  eprint        = {2112.10741},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{2023dalle2,
  title  = {Dall-e-2},
  author = {OpenAI},
  year   = 2023,
  url    = {https://openai.com/product/dall-e-2}
}
@misc{2023midjourney,
  title  = {Midjourney},
  author = {Midjourney},
  year   = 2023,
  url    = {https://www.midjourney.com/}
}
@inproceedings{parmar2023zeroshotimagetoimagetranslation,
  title     = {Zero-shot image-to-image translation},
  author    = {Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  year      = 2023,
  booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
  pages     = {1--11}
}
@inproceedings{Avrahami_2023,
  title     = {Spatext: Spatio-textual representation for controllable image generation},
  author    = {Avrahami, Omri and Hayes, Thomas and Gafni, Oran and Gupta, Sonal and Taigman, Yaniv and Parikh, Devi and Lischinski, Dani and Fried, Ohad and Yin, Xi},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {18370--18380}
}
@inproceedings{li2023gligenopensetgroundedtexttoimage,
  title     = {Gligen: Open-set grounded text-to-image generation},
  author    = {Li, Yuheng and Liu, Haotian and Wu, Qingyang and Mu, Fangzhou and Yang, Jianwei and Gao, Jianfeng and Li, Chunyuan and Lee, Yong Jae},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {22511--22521}
}
@misc{gal2022imageworthwordpersonalizing,
  title         = {An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion},
  author        = {Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit H. Bermano and Gal Chechik and Daniel Cohen-Or},
  year          = 2022,
  url           = {https://arxiv.org/abs/2208.01618},
  eprint        = {2208.01618},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{ruiz2023dreamboothfinetuningtexttoimage,
  title     = {Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author    = {Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {22500--22510}
}
@inproceedings{brooks2023instructpix2pixlearningfollowimage,
  title     = {Instructpix2pix: Learning to follow image editing instructions},
  author    = {Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {18392--18402}
}
@misc{huang2023regionawarediffusionzeroshottextdriven,
  title         = {Region-Aware Diffusion for Zero-shot Text-driven Image Editing},
  author        = {Nisha Huang and Fan Tang and Weiming Dong and Tong-Yee Lee and Changsheng Xu},
  year          = 2023,
  url           = {https://arxiv.org/abs/2302.11797},
  eprint        = {2302.11797},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{tumanyan2022plugandplaydiffusionfeaturestextdriven,
  title     = {Plug-and-play diffusion features for text-driven image-to-image translation},
  author    = {Tumanyan, Narek and Geyer, Michal and Bagon, Shai and Dekel, Tali},
  year      = 2023,
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {1921--1930}
}
@inproceedings{voynov2022sketchguidedtexttoimagediffusionmodels,
  title     = {Sketch-guided text-to-image diffusion models},
  author    = {Voynov, Andrey and Aberman, Kfir and Cohen-Or, Daniel},
  year      = 2023,
  booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
  pages     = {1--11}
}
@inproceedings{isola2018imagetoimagetranslationconditionaladversarial,
  title     = {Image-to-image translation with conditional adversarial networks},
  author    = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  year      = 2017,
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {1125--1134}
}
@inproceedings{wang2018highresolutionimagesynthesissemantic,
  title     = {High-resolution image synthesis and semantic manipulation with conditional gans},
  author    = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  year      = 2018,
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {8798--8807}
}
@inproceedings{zhou2021cocosnetv2fullresolutioncorrespondence,
  title     = {Cocosnet v2: Full-resolution correspondence learning for image translation},
  author    = {Zhou, Xingran and Zhang, Bo and Zhang, Ting and Zhang, Pan and Bao, Jianmin and Chen, Dong and Zhang, Zhongfei and Wen, Fang},
  year      = 2021,
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {11465--11475}
}
@article{zhu2018multimodalimagetoimagetranslation,
  title   = {Toward multimodal image-to-image translation},
  author  = {Zhu, Jun-Yan and Zhang, Richard and Pathak, Deepak and Darrell, Trevor and Efros, Alexei A and Wang, Oliver and Shechtman, Eli},
  year    = 2017,
  journal = {Advances in neural information processing systems},
  volume  = 30
}
@inproceedings{chen2021pretrainedimageprocessingtransformer,
  title     = {Pre-trained image processing transformer},
  author    = {Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  year      = 2021,
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {12299--12310}
}
@inproceedings{ramesh2021zeroshottexttoimagegeneration,
  title        = {Zero-shot text-to-image generation},
  author       = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  year         = 2021,
  journal      = {CoRR},
  booktitle    = {International conference on machine learning},
  volume       = {abs/2102.12092},
  pages        = {8821--8831},
  organization = {Pmlr}
}
@inproceedings{esser2021tamingtransformershighresolutionimage,
  title     = {Taming transformers for high-resolution image synthesis},
  author    = {Patrick Esser and Robin Rombach and Bjorn Ommer},
  year      = 2021,
  journal   = {CoRR},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  volume    = {abs/2012.09841},
  pages     = {12873--12883}
}
@inproceedings{saharia2022paletteimagetoimagediffusionmodels,
  title     = {Palette: Image-to-image diffusion models},
  author    = {Chitwan Saharia and William Chan and Huiwen Chang and Chris Lee and Jonathan Ho and Tim Salimans and David Fleet and Mohammad Norouzi},
  year      = 2022,
  booktitle = {ACM SIGGRAPH 2022 conference proceedings},
  pages     = {1--10}
}
@misc{wang2022pretrainingneedimagetoimagetranslation,
  title         = {Pretraining is All You Need for Image-to-Image Translation},
  author        = {Tengfei Wang and Ting Zhang and Bo Zhang and Hao Ouyang and Dong Chen and Qifeng Chen and Fang Wen},
  year          = 2022,
  url           = {https://arxiv.org/abs/2205.12952},
  eprint        = {2205.12952},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{richardson2021encodingstylestyleganencoder,
  title     = {Encoding in style: a stylegan encoder for image-to-image translation},
  author    = {Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
  year      = 2021,
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {2287--2296}
}
@misc{ho2022classifierfreediffusionguidance,
  title         = {Classifier-Free Diffusion Guidance},
  author        = {Jonathan Ho and Tim Salimans},
  year          = 2022,
  url           = {https://arxiv.org/abs/2207.12598},
  eprint        = {2207.12598},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{schuhmann2021laion400mopendatasetclipfiltered,
  title         = {LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs},
  author        = {Christoph Schuhmann and Richard Vencu and Romain Beaumont and Robert Kaczmarczyk and Clayton Mullis and Aarush Katta and Theo Coombes and Jenia Jitsev and Aran Komatsuzaki},
  year          = 2021,
  url           = {https://arxiv.org/abs/2111.02114},
  eprint        = {2111.02114},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{pernias2024wrstchen,
  title     = {W\"urstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models},
  author    = {Pablo Pernias and Dominic Rampas and Mats Leon Richter and Christopher Pal and Marc Aubreville},
  year      = 2024,
  booktitle = {The Twelfth International Conference on Learning Representations},
  url       = {https://openreview.net/forum?id=gU58d5QeGv}
}
@misc{rombach2022sd_1_4,
  title        = {Stable diffusion 1.4 model card},
  author       = {Robin Rombach and Patrick Esser},
  year         = 2022,
  howpublished = {\url{https://huggingface.co/CompVis/stable-diffusion-v-1-4-original}}
}
@misc{rombach2023sd_2_1,
  title        = {Stable diffusion 2.1 model card},
  year         = 2023,
  author       = {Robin Rombach and Patrick Esser and David Ha},
  howpublished = {\url{https://huggingface.co/stabilityai/stable-diffusion-2-1}}
}
@misc{dreamlike_art2024,
  title        = {Dreamlike Photoreal 2.0 model card},
  year         = 2024,
  author       = {dreamlike-art},
  howpublished = {\url{https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0}}
}
@misc{rombach}
@inproceedings{xie2015holisticallynestededgedetection,
  title     = {Holistically-nested edge detection},
  author    = {Xie, Saining and Tu, Zhuowen},
  year      = 2015,
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {1395--1403}
}
@InProceedings{arjovsky2017wasserstein,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author =       {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {214--223},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/arjovsky17a.html},
  abstract = 	 {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.}
}
@inproceedings{bigganbrock,
  title     = {Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author    = {Andrew Brock and Jeff Donahue and Karen Simonyan},
  year      = 2019,
  booktitle = {International Conference on Learning Representations (ICLR)}
}
@inproceedings{DBLP:conf/icml/ChenRC0JLS20,
  title     = {Generative Pretraining from Pixels},
  author    = {Mark Chen and Alec Radford and Rewon Child and Jeffrey Wu and Heewoo Jun and David Luan and Ilya Sutskever},
  year      = 2020,
  booktitle = {Proceedings of Machine Learning Research (ICML)},
  publisher = {PMLR},
  volume    = 119,
  pages     = {1691--1703}
}
@article{DBLP:journals/corr/abs-2011-10650,
  title   = {Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images},
  author  = {Rewon Child},
  year    = 2020,
  journal = {CoRR},
  volume  = {abs/2011.10650}
}
@article{DBLP:journals/corr/abs-1904-10509,
  title   = {Generating Long Sequences with Sparse Transformers},
  author  = {Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
  year    = 2019,
  journal = {CoRR},
  volume  = {abs/1904.10509}
}
@inproceedings{DBLP:conf/iclr/DaiW19,
  title     = {Diagnosing and Enhancing VAE Models},
  author    = {Bin Dai and David~P. Wipf},
  year      = 2019,
  booktitle = {ICLR (Poster)},
  publisher = {OpenReview.net}
}
@inproceedings{dinh2015nice,
  author       = {Laurent Dinh and
                  David Krueger and
                  Yoshua Bengio},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {{NICE:} Non-linear Independent Components Estimation},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1410.8516},
  timestamp    = {Fri, 02 Aug 2024 11:44:53 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DinhKB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/iclr/DinhSB17,
  title     = {Density Estimation Using Real NVP},
  author    = {Laurent Dinh and Jascha Sohl{-}Dickstein and Samy Bengio},
  year      = 2017,
  booktitle = {5th International Conference on Learning Representations (ICLR)},
  publisher = {OpenReview.net},
  address   = {Toulon, France}
}
@article{goodfellow2014GAN,
  title   = {Generative Adversarial Networks},
  author  = {Ian~J. Goodfellow and Jean Pouget{-}Abadie and Mehdi Mirza and Bing Xu and David Warde{-}Farley and Sherjil Ozair and Aaron~C. Courville and Yoshua Bengio},
  year    = 2014,
  journal = {CoRR}
}
@article{gulrajani2017improved,
  title={Improved Training of Wasserstein GANs}, 
  author={Ishaan Gulrajani and Faruk Ahmed and Martin Arjovsky and Vincent Dumoulin and Aaron Courville},
  year={2017},
  eprint={1704.00028},
  journal={arXiv},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1704.00028}, 
}
@article{DBLP:journals/corr/abs-2106-15282,
  title   = {Cascaded Diffusion Models for High Fidelity Image Generation},
  author  = {Jonathan Ho and Chitwan Saharia and William Chan and David~J. Fleet and Mohammad Norouzi and Tim Salimans},
  year    = 2021,
  journal = {CoRR},
  volume  = {abs/2106.15282}
}
@article{DBLP:journals/corr/abs-1912-04958,
  title   = {Analyzing and Improving the Image Quality of StyleGAN},
  author  = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  year    = 2019,
  journal = {CoRR},
  volume  = {abs/1912.04958}
}
@inproceedings{glow,
  title     = {Glow: Generative Flow with Invertible 1x1 Convolutions},
  author    = {Durk~P Kingma and Prafulla Dhariwal},
  year      = 2018,
  booktitle = {Advances in Neural Information Processing Systems}
}
@inproceedings{VAE,
  title     = {Auto-Encoding Variational Bayes},
  author    = {Diederik~P. Kingma and Max Welling},
  year      = 2014,
  booktitle = {2nd International Conference on Learning Representations (ICLR)}
}
@article{DBLP:journals/corr/abs-2106-00132,
  title   = {On Fast Sampling of Diffusion Probabilistic Models},
  author  = {Zhifeng Kong and Wei Ping},
  year    = 2021,
  journal = {CoRR},
  volume  = {abs/2106.00132}
}
@article{DBLP:journals/corr/abs-1801-04406,
  title   = {On the Convergence Properties of GAN Training},
  author  = {Lars~M. Mescheder},
  year    = 2018,
  journal = {CoRR},
  volume  = {abs/1801.04406}
}
@inproceedings{DBLP:conf/nips/RazaviOV19,
  title     = {Generating Diverse High-Fidelity Images with VQ-VAE-2},
  author    = {Ali Razavi and A{\"{a}}ron van~den Oord and Oriol Vinyals},
  year      = 2019,
  booktitle = {NeurIPS},
  pages     = {14837--14847}
}
@inproceedings{DBLP:conf/nips/RombachEO20,
  title     = {Network-to-Network Translation with Conditional Invertible Neural Networks},
  author    = {Robin Rombach and Patrick Esser and Bj{\"{o}}rn Ommer},
  year      = 2020,
  booktitle = {NeurIPS}
}
@article{DBLP:journals/corr/abs-2104-02600,
  title   = {Noise Estimation for Generative Diffusion Models},
  author  = {Robin San{-}Roman and Eliya Nachmani and Lior Wolf},
  year    = 2021,
  journal = {CoRR},
  volume  = {abs/2104.02600}
}
@inproceedings{DBLP:conf/iclr/SongME21,
  title     = {Denoising Diffusion Implicit Models},
  author    = {Jiaming Song and Chenlin Meng and Stefano Ermon},
  year      = 2021,
  booktitle = {ICLR},
  publisher = {OpenReview.net}
}
@article{DBLP:journals/corr/abs-2011-13456,
  title   = {Score-Based Generative Modeling through Stochastic Differential Equations},
  author  = {Yang Song and Jascha Sohl{-}Dickstein and Diederik~P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  year    = 2020,
  journal = {CoRR},
  volume  = {abs/2011.13456}
}
@inproceedings{DBLP:conf/nips/VahdatK20,
  title     = {NVAE: A Deep Hierarchical Variational Autoencoder},
  author    = {Arash Vahdat and Jan Kautz},
  year      = 2020,
  booktitle = {NeurIPS}
}
@article{DBLP:journals/corr/abs-2106-05931,
  title   = {Score-Based Generative Modeling in Latent Space},
  author  = {Arash Vahdat and Karsten Kreis and Jan Kautz},
  year    = 2021,
  journal = {CoRR},
  volume  = {abs/2106.05931}
}
@inproceedings{NIPS2016_b1301141,
  title     = {Conditional Image Generation with PixelCNN Decoders},
  author    = {Aaron van~den Oord and Nal Kalchbrenner and Lasse Espeholt and Koray Kavukcuoglu and Oriol Vinyals and Alex Graves},
  year      = 2016,
  booktitle = {Advances in Neural Information Processing Systems}
}
@article{DBLP:journals/corr/OordKK16,
  title   = {Pixel Recurrent Neural Networks},
  author  = {A{\"{a}}ron van~den Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
  year    = 2016,
  journal = {CoRR},
  volume  = {abs/1601.06759}
}
@article{DBLP:journals/corr/abs-2104-10157,
  title   = {VideoGPT: Video Generation Using VQ-VAE and Transformers},
  author  = {Wilson Yan and Yunzhi Zhang and Pieter Abbeel and Aravind Srinivas},
  year    = 2021,
  journal = {CoRR},
  volume  = {abs/2104.10157}
}
@article{yu2021vectorquantized,
  title={Vector-quantized Image Modeling with Improved VQGAN},
  author={Jiahui Yu and Xin Li and Jing Yu Koh and Han Zhang and Ruoming Pang and James Qin and Alexander Ku and Yuanzhong Xu and Jason Baldridge and Yonghui Wu},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.04627},
  url={https://api.semanticscholar.org/CorpusID:238582653}
}
@inproceedings{vdOord2017NeuralDiscreteRepresentationLearning,
  title     = {Neural discrete representation learning},
  author    = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
  year      = 2017,
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  location  = {Long Beach, California, USA},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  series    = {NIPS'17},
  pages     = {6309–6318},
  isbn      = 9781510860964,
  abstract  = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -ߞ where the latents are ignored when they are paired with a powerful autoregressive decoder -ߞ typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
  numpages  = 10
}
@article{Tan2021EfficientNetV2,
  title   = {EfficientNetV2: Smaller Models and Faster Training},
  author  = {Tan, Mingxing and Le, Quoc},
  year    = 2021,
  month   = {04},
  journal = {arXiv},
  pages   = {},
  doi     = {10.48550/arXiv.2104.00298}
}
@inproceedings{Nichol2021ImprovedDenoisingDiffusionProbabilisticModels,
  title     = {Improved Denoising Diffusion Probabilistic Models},
  author    = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
  year      = 2021,
  month     = {18--24 Jul},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = 139,
  pages     = {8162--8171},
  url       = {https://proceedings.mlr.press/v139/nichol21a.html},
  editor    = {Meila, Marina and Zhang, Tong},
  pdf       = {http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf},
  abstract  = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code and pre-trained models at https://github.com/openai/improved-diffusion.}
}
@article{Ilharco2021OpenCLIP,
  title   = {OpenCLIP (0.1)},
  author  = {Gabriel Ilharco and Mitchell Wortsman and Nicholas Carlini and Rohan Taori and Achal Dave and Vaishaal Shankar and Hongseok Namkoong and John Miller and Hannaneh Hajishirzi and Ali Farhadi and Ludwig Schmidt},
  year    = 2021,
  journal = {Zenodo},
  doi     = {https://doi.org/10.5281/zenodo.5143773}
}
@inproceedings{kirstain2023pickapic,
  title     = {Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation},
  author    = {Yuval Kirstain and Adam Polyak and Uriel Singer and Shahbuland Matiana and Joe Penna and Omer Levy},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year      = {2023},
  url       = {https://openreview.net/forum?id=G5RwHpBUv0}
}
@inproceedings{podell2024sdxl,
  title={{SDXL}: Improving Latent Diffusion Models for High-Resolution Image Synthesis},
  author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas M{\"u}ller and Joe Penna and Robin Rombach},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=di52zR8xgf}
}
@article{kullback1951OnInformationandSufficiency,
  author = {S. Kullback and R. A. Leibler},
  title = {{On Information and Sufficiency}},
  volume = {22},
  journal = {The Annals of Mathematical Statistics},
  number = {1},
  publisher = {Institute of Mathematical Statistics},
  pages = {79 -- 86},
  year = {1951},
  doi = {10.1214/aoms/1177729694},
  URL = {https://doi.org/10.1214/aoms/1177729694}
}
@inproceedings{Ouyang2024InstructGPT,
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  title = {Training language models to follow instructions with human feedback},
  year = {2024},
  isbn = {9781713871088},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
  booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
  articleno = {2011},
  numpages = {15},
  location = {New Orleans, LA, USA},
  series = {NIPS '22}
}