\subsection{The Average Human Rating of ControlNet}
\subsubsection{User Study}

We conducted a user study to evaluate the performance of ControlNet compared to PITI~\cite{wang2022pretrainingneedimagetoimagetranslation} in generating images from hand-drawn sketches. Unlike the original ControlNet study~\cite{zhang2023addingconditionalcontroltexttoimage}, which included Sketch-Guided Diffusion (SGD)~\cite{voynov2022sketchguidedtexttoimagediffusionmodels} and a lighter version of ControlNet (ControlNet-lite), we were limited to PITI and ControlNet because the authors of SGD did not provide a model, and retraining it was not feasible. Additionally, the ControlNet-lite model was unavailable. In the original paper the authors mention both, Stable Diffusion (SD) V1.5 and Stable Diffusion V2 as backbones for ControlNet. However, they do not indicate which version of Stable Diffusion is used for the experiment. As the authors official GitHub "https://github.com/lllyasviel/ControlNet" contains the setup instructions for ControlNet + SD V1.5 and we could not find any indication of Stable Diffusion V2, we opted for SD V1.5 for our experiment. Furthermore, unlike PITI, which was trained on the MS-COCO dataset~\cite{lin2015microsoftcococommonobjects} only including photos, ControlNet can also generate images in different styles, i.e.\ cartoons and paintings, due to the fact that SD V1.5 was trained on the LAION-400M dataset \cite{schuhmann2021laion400mopendatasetclipfiltered}. While the original experiments goal was to evaluate the methods performance on sketch inputs only (wihtout prompts), we also evaluate the difference of ControlNets images generated with simple prompts and with no prompts, because without prompts ControlNet may produce stylized outputs. We use the prompt \textcolor{red}{``INSERT PROMPT HERE''}, as it does not hint at specific objects of the image but implicitly tells ControlNet to generate high quality, non-stylized images. 
% The ranking of images without stylization 

For this study, we sampled 20 unseen hand-drawn sketches and used them to generate images with PITI, ControlNet and ControlNet + prompt. We recruited \textcolor{red}{NUMBER OF USERS} users to rank each generated image based on two criteria: “the quality of displayed images” and “the fidelity to the sketch,” following a protocol similar to the original study. Participants ranked each image on a scale from 1 to 5, where lower scores indicate worse performance, resulting in \textcolor{red}{120 / NUMBER OF RANKINGS} rankings for each criterion (quality and fidelity).

To quantify user preferences, we computed the Average Human Ranking (AHR) for both metrics, which served as a comparative measure of how well each model adhered to the sketches and the overall image quality. Due to the constraints in model availability, our study focused on comparing the performance of PITI and ControlNet, without including comparisons with SGD and ControlNet-lite.
